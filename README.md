# Queue Microservice Case Study

Um projeto completo de estudo de arquitetura de microserviÃ§os com foco em mensageria, resiliÃªncia e chaos engineering, utilizando Kubernetes como ambiente de execuÃ§Ã£o.

## ğŸ¯ Objetivos

Este projeto foi criado para permitir a comparaÃ§Ã£o prÃ¡tica entre diferentes sistemas de mensageria (principalmente Kafka e RabbitMQ), sem que os microsserviÃ§os fiquem acoplados diretamente a nenhuma dessas tecnologias. A troca do broker deve ser possÃ­vel apenas por configuraÃ§Ã£o de variÃ¡veis de ambiente, sem alteraÃ§Ãµes no core da aplicaÃ§Ã£o.

## ğŸ—ï¸ Arquitetura

O sistema Ã© composto por mÃºltiplos microsserviÃ§os:

### 1. API Gateway (NestJS/TypeScript)
- **Responsabilidade**: Expor endpoints HTTP
- **Funcionalidades**:
  - Recebe requisiÃ§Ãµes externas
  - Valida dados de entrada
  - Gera `correlation_id` e `idempotency_id`
  - Publica eventos `message.created`
  - ExpÃµe endpoint de consulta de status (`GET /messages/:id/status`)

### 2. Message Processor (Go)
- **Responsabilidade**: Processar mensagens
- **Funcionalidades**:
  - Consome eventos `message.created`
  - Implementa idempotÃªncia explÃ­cita
  - Processa mensagens e atualiza status no banco
  - Publica eventos `message.status.updated`

### 3. Notification Service (Go)
- **Responsabilidade**: NotificaÃ§Ãµes
- **Funcionalidades**:
  - Consome eventos `message.status.updated`
  - Registra logs/notificaÃ§Ãµes

### 4. PostgreSQL
- **Responsabilidade**: Armazenar estado e histÃ³rico
- **Tabelas**:
  - `messages`: Estado atual das mensagens (idempotency_id como chave primÃ¡ria)
  - `message_history`: HistÃ³rico completo de mudanÃ§as de status

## ğŸ“‹ Contrato de Eventos

Todos os eventos trocados entre os serviÃ§os seguem um contrato Ãºnico e obrigatÃ³rio:

```json
{
  "event_id": "string (Ãºnico)",
  "correlation_id": "string (gerado pela API)",
  "idempotency_id": "string (gerado pela API)",
  "event_type": "string (ex: message.created, message.status.updated)",
  "source_service": "string (nome do serviÃ§o)",
  "timestamp": "string (ISO-8601)",
  "payload": {
    // Dados especÃ­ficos do evento
  }
}
```

**Importante**: Todos esses campos sÃ£o obrigatÃ³rios e devem ser propagados em todos os serviÃ§os, logs, mensagens de erro e eventos enviados para DLQ.

## ğŸ”„ Dead Letter Queue (DLQ)

O sistema implementa Dead Letter Queue de forma explÃ­cita:

- **Kafka**: TÃ³picos especÃ­ficos terminados em `.dlq` (ex: `message.created.dlq`)
- **RabbitMQ**: Dead Letter Exchange (`dlx`) com filas dedicadas (ex: `message.created.dlq`)

Quando uma mensagem falha definitivamente apÃ³s tentativas de processamento, o evento original Ã© enviado para a DLQ acompanhado do erro ocorrido e do contexto completo (incluindo `correlation_id` e `idempotency_id`).

## ğŸ” IdempotÃªncia

Todos os consumidores escritos em Go implementam idempotÃªncia de forma explÃ­cita:

1. Antes de processar qualquer mensagem, o serviÃ§o verifica no banco se aquele `idempotency_id` jÃ¡ foi processado
2. Caso positivo, a mensagem Ã© ignorada de forma segura
3. Caso negativo, o processamento ocorre normalmente e o estado Ã© persistido

Isso garante que, mesmo com falhas, retries ou reentregas causadas por Kafka, RabbitMQ ou falhas induzidas por chaos engineering, o sistema nÃ£o produza efeitos colaterais duplicados.

## ğŸš€ Como Subir o Cluster Localmente

### PrÃ©-requisitos

- Kubernetes (minikube, kind, ou Docker Desktop com Kubernetes habilitado)
- kubectl configurado
- Docker para build das imagens

### 1. Build das Imagens

```bash
# Build da API Gateway
cd api-gateway
docker build -t api-gateway:latest .

# Build do Message Processor
cd ../message-processor
docker build -t message-processor:latest .

# Build do Notification Service
cd ../notification-service
docker build -t notification-service:latest .
```

### 2. Deploy no Kubernetes

```bash
# Deploy do PostgreSQL
kubectl apply -f k8s/postgresql/deployment.yaml

# Deploy do Kafka (ou RabbitMQ)
kubectl apply -f k8s/kafka/deployment.yaml
# OU
kubectl apply -f k8s/rabbitmq/deployment.yaml

# Aguardar serviÃ§os estarem prontos
kubectl wait --for=condition=ready pod -l app=postgresql --timeout=120s
kubectl wait --for=condition=ready pod -l app=kafka --timeout=120s

# Deploy dos microsserviÃ§os
kubectl apply -f k8s/api-gateway/deployment.yaml
kubectl apply -f k8s/message-processor/deployment.yaml
kubectl apply -f k8s/notification-service/deployment.yaml
```

### 3. Verificar Status

```bash
# Ver pods
kubectl get pods

# Ver logs do API Gateway
kubectl logs -f deployment/api-gateway

# Ver logs do Message Processor
kubectl logs -f deployment/message-processor

# Ver logs do Notification Service
kubectl logs -f deployment/notification-service
```

## ğŸ”€ Alternando entre Kafka e RabbitMQ

A troca do broker Ã© feita exclusivamente por variÃ¡vel de ambiente `MESSAGE_BROKER`:

### Para usar Kafka (padrÃ£o):
```yaml
env:
- name: MESSAGE_BROKER
  value: "kafka"
```

### Para usar RabbitMQ:
```yaml
env:
- name: MESSAGE_BROKER
  value: "rabbit"  # ou "rabbitmq"
```

**Importante**: Todos os serviÃ§os devem usar o mesmo broker. Para alternar:

1. Edite os manifests em `k8s/*/deployment.yaml`
2. Altere a variÃ¡vel `MESSAGE_BROKER` em todos os serviÃ§os
3. Aplique os manifests novamente: `kubectl apply -f k8s/`

## ğŸ§ª Executando Experimentos de Chaos

### Instalar Chaos Mesh

```bash
curl -sSL https://mirrors.chaos-mesh.org/latest/install.sh | bash
```

### Experimentos DisponÃ­veis

#### 1. Pod Kill (mata pods do message-processor a cada 2 minutos)
```bash
kubectl apply -f chaos/pod-kill.yaml
```

#### 2. Pod Failure (falha 50% dos pods workers por 30 segundos)
```bash
kubectl apply -f chaos/pod-failure.yaml
```

#### 3. Network Latency (adiciona 100ms de latÃªncia)
```bash
kubectl apply -f chaos/network-latency.yaml
```

#### 4. Network Partition (particiona 30% dos workers por 2 minutos)
```bash
kubectl apply -f chaos/network-partition.yaml
```

#### 5. Database Failure (mata PostgreSQL a cada 5 minutos)
```bash
kubectl apply -f chaos/database-failure.yaml
```

#### 6. Broker Failure (mata broker a cada 3 minutos)
```bash
kubectl apply -f chaos/broker-failure.yaml
```

#### 7. Chaos Monkey (mata aleatoriamente atÃ© 10% dos workers a cada minuto)
```bash
kubectl apply -f chaos/chaos-monkey.yaml
```

### Verificar Status dos Experimentos

```bash
kubectl get podchaos
kubectl get networkchaos
```

### Remover Experimentos

```bash
kubectl delete -f chaos/<experiment-name>.yaml
```

## ğŸ“Š Validando DLQ

### Kafka

```bash
# Listar tÃ³picos DLQ
kubectl exec -it <kafka-pod> -- kafka-topics --list --bootstrap-server localhost:9092 | grep dlq

# Consumir mensagens da DLQ
kubectl exec -it <kafka-pod> -- kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic message.created.dlq \
  --from-beginning
```

### RabbitMQ

```bash
# Acessar interface de gerenciamento
kubectl port-forward svc/rabbitmq 15672:15672

# Acessar http://localhost:15672 (guest/guest)
# Verificar filas terminadas em .dlq
```

## ğŸ§ª Testando o Fluxo Completo

### 1. Criar uma Mensagem

```bash
# Obter IP do LoadBalancer
API_URL=$(kubectl get svc api-gateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
# Ou use port-forward se nÃ£o tiver LoadBalancer
kubectl port-forward svc/api-gateway 8080:80

# Criar mensagem
curl -X POST http://localhost:8080/messages \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Test message",
    "metadata": {
      "source": "test"
    }
  }'

# Resposta:
# {
#   "id": "idempotency_id",
#   "correlation_id": "correlation_id",
#   "idempotency_id": "idempotency_id",
#   "status": "pending"
# }
```

### 2. Consultar Status

```bash
# Usar o id retornado na criaÃ§Ã£o
curl http://localhost:8080/messages/{id}/status

# Resposta:
# {
#   "id": "idempotency_id",
#   "correlation_id": "correlation_id",
#   "status": "processed",
#   "created_at": "...",
#   "updated_at": "...",
#   "history": [
#     {
#       "status": "pending",
#       "service": "api-gateway",
#       "timestamp": "..."
#     },
#     {
#       "status": "processing",
#       "service": "message-processor",
#       "timestamp": "..."
#     },
#     {
#       "status": "processed",
#       "service": "message-processor",
#       "timestamp": "..."
#     }
#   ]
# }
```

### 3. Rastrear por Correlation ID

```bash
# Consultar logs com correlation_id
kubectl logs -l app=api-gateway | grep "correlation_id"
kubectl logs -l app=message-processor | grep "correlation_id"
kubectl logs -l app=notification-service | grep "correlation_id"
```

## ğŸ“ Logs Estruturados

Todos os serviÃ§os geram logs estruturados em JSON com os seguintes campos obrigatÃ³rios:

- `level`: NÃ­vel do log (INFO, ERROR, WARN, DEBUG)
- `service`: Nome do serviÃ§o
- `correlation_id`: ID de correlaÃ§Ã£o (quando disponÃ­vel)
- `idempotency_id`: ID de idempotÃªncia (quando disponÃ­vel)
- `message`: Mensagem do log
- `timestamp`: Timestamp ISO-8601
- `additional_data`: Dados adicionais (opcional)

Exemplo:
```json
{
  "level": "INFO",
  "service": "message-processor",
  "correlation_id": "abc-123",
  "idempotency_id": "def-456",
  "message": "Message processed successfully",
  "timestamp": "2024-01-15T10:30:00Z",
  "additional_data": {
    "status": "processed"
  }
}
```

## ğŸ·ï¸ Labels Kubernetes

Todos os recursos Kubernetes possuem labels bem definidas para facilitar seleÃ§Ã£o e aplicaÃ§Ã£o de experimentos de caos:

- `app`: Nome da aplicaÃ§Ã£o
- `tier`: Camada (api, worker, database, messaging)
- `lang`: Linguagem (typescript, go, sql)

Exemplos de seleÃ§Ã£o:
```bash
# Selecionar todos os workers
kubectl get pods -l tier=worker

# Selecionar serviÃ§os Go
kubectl get pods -l lang=go

# Aplicar chaos apenas em workers
kubectl apply -f chaos/pod-kill.yaml  # Configurado para tier=worker
```

## ğŸ“ Estrutura do Projeto

```
queue-microservice-case/
â”œâ”€â”€ api-gateway/              # API Gateway (NestJS/TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ message-processor/         # Message Processor (Go)
â”‚   â”œâ”€â”€ main.go
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ go.mod
â”œâ”€â”€ notification-service/      # Notification Service (Go)
â”‚   â”œâ”€â”€ main.go
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ go.mod
â”œâ”€â”€ shared/                    # CÃ³digo compartilhado
â”‚   â”œâ”€â”€ contracts/            # Contrato de eventos
â”‚   â”œâ”€â”€ messaging/            # AbstraÃ§Ã£o de mensageria
â”‚   â”œâ”€â”€ database/             # RepositÃ³rio de banco
â”‚   â””â”€â”€ logger/               # Logger estruturado
â”œâ”€â”€ k8s/                      # Manifests Kubernetes
â”‚   â”œâ”€â”€ api-gateway/
â”‚   â”œâ”€â”€ message-processor/
â”‚   â”œâ”€â”€ notification-service/
â”‚   â”œâ”€â”€ postgresql/
â”‚   â”œâ”€â”€ kafka/
â”‚   â””â”€â”€ rabbitmq/
â”œâ”€â”€ chaos/                     # Experimentos Chaos Mesh
â”‚   â”œâ”€â”€ pod-kill.yaml
â”‚   â”œâ”€â”€ network-latency.yaml
â”‚   â”œâ”€â”€ chaos-monkey.yaml
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

## ğŸ”§ VariÃ¡veis de Ambiente

### API Gateway
- `PORT`: Porta do servidor (padrÃ£o: 3000)
- `MESSAGE_BROKER`: Tipo de broker (kafka, rabbit, rabbitmq)
- `KAFKA_BROKERS`: Lista de brokers Kafka (ex: "localhost:9092")
- `RABBITMQ_URL`: URL do RabbitMQ (ex: "amqp://guest:guest@localhost:5672/")
- `DB_HOST`, `DB_PORT`, `DB_USER`, `DB_PASSWORD`, `DB_NAME`: ConfiguraÃ§Ãµes do PostgreSQL

### Message Processor / Notification Service
- `MESSAGE_BROKER`: Tipo de broker (kafka, rabbit, rabbitmq)
- `KAFKA_BROKERS`: Lista de brokers Kafka
- `RABBITMQ_URL`: URL do RabbitMQ
- `DB_*`: ConfiguraÃ§Ãµes do PostgreSQL (apenas message-processor)

## ğŸ“ Conceitos Demonstrados

Este projeto demonstra na prÃ¡tica:

1. **Arquitetura de MicroserviÃ§os**: SeparaÃ§Ã£o de responsabilidades, comunicaÃ§Ã£o assÃ­ncrona
2. **AbstraÃ§Ã£o de DependÃªncias**: Troca de broker sem alterar cÃ³digo core
3. **IdempotÃªncia**: Garantia de processamento Ãºnico mesmo com retries
4. **Rastreabilidade**: Correlation ID e Idempotency ID propagados em toda a cadeia
5. **Dead Letter Queue**: Tratamento de mensagens com falha definitiva
6. **ResiliÃªncia**: Sistema preparado para falhas e recuperaÃ§Ã£o
7. **Chaos Engineering**: Testes de resiliÃªncia com Chaos Mesh
8. **Observabilidade**: Logs estruturados para rastreamento completo
9. **Kubernetes**: Deploy e orquestraÃ§Ã£o de microserviÃ§os
10. **Event-Driven Architecture**: ComunicaÃ§Ã£o baseada em eventos

## âš ï¸ Notas Importantes

- Este Ã© um projeto de **estudo e experimentaÃ§Ã£o**, nÃ£o uma aplicaÃ§Ã£o de produÃ§Ã£o
- O foco estÃ¡ em demonstrar conceitos arquiteturais, nÃ£o performance ou escalabilidade extrema
- Alguns recursos podem ser simplificados para facilitar o entendimento (ex: PostgreSQL sem HA)
- Sempre teste em ambientes nÃ£o-produtivos antes de aplicar em produÃ§Ã£o

## ğŸ“š ReferÃªncias

- [NestJS Documentation](https://docs.nestjs.com/)
- [Go Documentation](https://go.dev/doc/)
- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [RabbitMQ Documentation](https://www.rabbitmq.com/documentation.html)
- [Chaos Mesh Documentation](https://chaos-mesh.org/docs/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)

## ğŸ“„ LicenÃ§a

MIT

